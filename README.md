This repo includes my work with UCLA's StarAI Lab, mentored by Professor Van den Broeck. 
The code is adapted from the lab's MoAT paper (https://starai.cs.ucla.edu/papers/SelvamAISTATS23.pdf), which describes a probabilistic model over spanning trees. 
As the original code only deals with for binary variables, I aim to extend this framework to paramaterize categorical distributions and implement a copula-fitting procedure (Iterated Proportional Fitting Procedure). 
We believe this will reduce computational cost during gradient steps and improve stability in training. 

Currently, I am implementing and testing a baseline model for the categorical case (as described in the MoAT paper's appendix) that involves l-1 trainable parameters (which we label as lambdas) for for l categories. Note that a fully general parameterization requires (l-1)^2 parameters, so it scales quadratically while the lambda paramaterization scales linearly (and thus captures less and less "information" from the distribution). So, it seems intuitive that we'll observe an increasing "performance gap" in the lambda baseline as l increases. I am interested in quantifying this initial performance gap and will build incrementally from there to eventually implement the general categorical parameterization. 
